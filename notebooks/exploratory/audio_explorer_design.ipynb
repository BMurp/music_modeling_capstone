{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.insert(0, '../../')\n",
    "from library.notebook_api.data_loader import  ModelDataLoader,CombinedDataLoader\n",
    "from library.source_data.feature_extractor import AudioFeatureExtractor\n",
    "from library.source_data.parallel_processor import AudioParallelProcessor\n",
    "import librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/murphybre/Desktop/UMichigan/Fall2024/siads699_capstone/music_modeling_capstone/notebooks/exploratory/../../library/notebook_api/data_loader.py:27: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  self.df_filtered = self.df_files_available[self.df.label.isnull() ==False ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracks in meta 107574\n",
      "tracks with files available in project_data_path:  9000\n",
      "tracks with top level genres available 50598\n",
      "tracks with genres and files (df_filtered) 9000\n"
     ]
    }
   ],
   "source": [
    "#instantate data_loader and the dataframes it makes available \n",
    "data_loader = CombinedDataLoader('small')\n",
    "df = data_loader.df\n",
    "df_files_available = data_loader.df_files_available\n",
    "df_genres_available = data_loader.df_genres_available\n",
    "df_filtered = data_loader.df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = AudioFeatureExtractor(df_filtered.head(5))\n",
    "audio.add_audio_data_to_df()\n",
    "audio.add_numerical_features_to_df()\n",
    "audio.add_mfcc_to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('my_array.npy',np.array(audio.df['mfcc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load('my_array.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 2582)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_mfcc(audio_and_sampling_rate):\n",
    "    y, sr = audio_and_sampling_rate[0],audio_and_sampling_rate[1]\n",
    "    return librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_new_mfcc(audio_and_sampling_rate):\n",
    "    y, sr = audio_and_sampling_rate[0],audio_and_sampling_rate[1]\n",
    "    #return librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "    mels = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512)\n",
    "    mels_db = librosa.power_to_db(S=mels, ref=1.0)\n",
    "    return mels_db\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 2585)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio.df['audio_and_sampling_rate'].apply(get_original_mfcc).iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 2585)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio.df['audio_and_sampling_rate'].apply(get_new_mfcc).iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
